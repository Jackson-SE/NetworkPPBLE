x = x,
fx = fx,
mean_function_model = 1,
initial = list( rep( 1, 2 ), 0.001 )
)
f <- function(x){ c( x[2] * sin( x[1] ) + x[1] * cos( x[2] ), 2 * x[1] + 3 * x[2] / x[1] ) }
x <- matrix( runif( 20, 0.2, 1.2 ), ncol = 2 )
fx <- t( apply( x, 1, f ) )
CL_ML( CF = NetworkPPBLE::GaussianCF,
CF_para = list(),
para_to_optim = c( "theta", "delta" ),
x = x,
fx = fx,
mean_function_model = 1,
initial = list( rep( 1, 2 ), 0.001 )
)
CL_ML( CF = NetworkPPBLE::GaussianCF,
CF_para = list(),
para_to_optim = c( "theta", "delta" ),
x = x,
fx = fx,
mean_function_model = 1,
initial = list( rep( 1, 2 ), 0.001 )
)
f <- function(x){ c( x[2] * sin( x[1] ) + x[1] * cos( x[2] ), 2 * x[1] + 3 * x[2] / x[1] ) }
x <- matrix( runif( 20, 0.2, 1.2 ), ncol = 2 )
fx <- t( apply( x, 1, f ) )
CL_ML( CF = NetworkPPBLE::GaussianCF,
CF_para = list(),
para_to_optim = c( "theta", "delta" ),
x = x,
fx = fx,
mean_function_model = 1,
initial = list( rep( 1, 2 ), 0.001 )
)
library(NetworkPPBLE)
devtools::load_all(".")
document()
library(NetworkPPBLE)
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
f <- function(x){ c( x[2] * sin( x[1] ) + x[1] * cos( x[2] ), 2 * x[1] + 3 * x[2] / x[1] ) }
x <- matrix( runif( 20, 0.2, 1.2 ), ncol = 2 )
fx <- t( apply( x, 1, f ) )
theta <- c(0.4, 0.6)
emulator <- emulate( x = x, fx = fx, CF = GaussianCF,
CF_para = list( theta = theta, delta = 0.0001 ) )
emulator2 <- emulate( x = x, fx = fx[,1], CF_para = list( theta = theta, delta = 0.0001 ) )
X <- data.frame( x )
dimnames( X )[[2]] <- c( "X1", "X2" )
emulator3 <- emulate( x = X, fx = fx, CF = GaussianCF,
CF_para = list( theta = theta, delta = 0.0001 ) )
emulator4 <- emulate( x = x, fx = fx, CF = GaussianCF,
CF_para = list( theta = NA, delta = 0.0001 ),
CF_para_optim = CL_ML,
CF_para_optim_para = list( mean_function_model = 1,
initial = rep( 1, 2 ) ) )
emulator4 <- emulate( x = x, fx = fx, CF = GaussianCF,
CF_para = list( theta = NA, delta = NA ),
CF_para_optim = CL_ML,
CF_para_optim_para = list( mean_function_model = 1,
initial = list( rep( 1, 2 ), 0.001 ) ) )
CF = GaussianCF
CF_para = list( theta = NA, delta = NA )
CF_para_optim = CL_ML
CF_para_optim_para = list( mean_function_model = 1,
initial = list( rep( 1, 2 ), 0.001 ) )
mean_function_model = 1
s2 = NA
# Check input conditions.
if( ( is.matrix( x ) | is.data.frame ( x ) ) == FALSE ){ stop( "x should be a matrix or a dataframe." ) }
if( ( is.vector( fx ) | is.matrix ( fx ) ) == FALSE ){ stop( "fx should be a vector or a matrix." ) }
if( NROW( x ) != NROW( fx ) ){ stop( "The number of rows of x should be equal to the number of rows of fx." ) }
# Calculate the number of rows of x.
n <- NROW( x )
# Obtain model matrix G from mean_function_model.
G <- NetworkPPBLE::model_matrix( x = x, model = mean_function_model )
# Number of columns of G
m <- NCOL( G )
# Put the formals of the first two elements of CF as x.
formals( CF )[1:2] <- list( x, x )
# Find the names of which parameters to the acceptance probability generator function were defined as NA.  We are going to optimise these ones.
para_to_optim <- names( which( is.na( CF_para ) ) )
para_to_optim
para_to_optim[2]
# Set the formals for the parameter optimisation function.
formals( CF_para_optim )[1:3] <- list( CF, CF_para, para_to_optim )
CF_para_optim
# Check if the formals of CF_para_optim are defined.
for( i in 1:length( formals( CF_para_optim ) ) ){
# This asks if both each formal of CF_para_optim has no default and is not provided in the CF_para_optim_para parameter list.
if( identical( formals( CF_para_optim )[[i]], substitute() ) & ( names( formals( CF_para_optim ) )[[i]] %in% names( CF_para_optim_para ) ) == FALSE ){
# If so, ask if the argument could also be given in the call of the outer function (in this case emulate itself).
if( assertthat::has_args( f = NetworkPPBLE::emulate, args = names( formals( CF_para_optim ) )[[i]] ) ){
# if it can, then we want to define it using this argument.
formals( CF_para_optim )[[i]] <- get( names( formals( CF_para_optim ) )[[i]] )
}else{
# otherwise we need to return an error explaining the problem as the function cannot continue.
stop( paste( "argument", names( formals( CF_para_optim ) )[[i]], "in CF_para_optim function not specified.", sep = " " ) )
}
}
}
length( formals( CF_para_optim ) )
CF_para_optim
names(CF_para_optim)
formals(CF_para_optim)
CF_para_optim_para
CF_para_optim
# Calculate the optimal parameters using the parameter optimisation function.
opt_par <- do.call( CF_para_optim, CF_para_optim_para )
opt_par
CF_para[[ para_to_optim ]]
devtools::load_all(".")
document()
devtools::load_all(".")
document()
library(NetworkPPBLE)
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
library(NetworkPPBLE)
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
library(NetworkPPBLE)
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
install.packages( c("assertthat", "rSPDE" ) )
devtools::load_all(".")
document()
library(NetworkPPBLE)
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
devtools::load_all(".")
dicument()
document()
devtools::load_all(".")
document()
library(NetworkPPBLE)
x = 1:100
Efx = matrix( c( x^(2.1/2), x^(2.2/2) ), nrow = 2, byrow=TRUE )
Varfx = matrix( c(x,x), nrow = 2, byrow = TRUE)
mean_sd_plot( x = x, Efx = Efx, Varfx = Varfx )
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
rep(1:2, 4)
devtools::load_all(".")
document()
devtools::load_all(".")
document()
library(NetworkPPBLE)
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
use_r( "CL_CV.r" )
devtools::load_all(".")
f <- function(x){ c( x[2] * sin( x[1] ) + x[1] * cos( x[2] ), 2 * x[1] + 3 * x[2] / x[1] ) }
x <- matrix( runif( 20, 0.2, 1.2 ), ncol = 2 )
fx <- t( apply( x, 1, f ) )
CF = NetworkPPBLE::GaussianCF
CF_para = list( delta = 0.0001 )
para_to_optim = "theta"
mean_function_model = 1
initial = rep( 1, 2 )
V_set_size = 10
V_splits = 10
G = NA
lower = -Inf
upper = Inf
method = "Nelder-Mead"
# Check input conditions.
if( NROW ( x ) != NROW ( fx ) ){ stop( "The number of rows of x and fx must be the same." ) }
if( identical( G, NA ) & identical( mean_function_model, NA ) ){ stop( "G and mean_function_model can't both be given as NAs." ) }
# Check that initial is a vector or a list of vectors.  If initial is a list, find the length of each of its elements and store as a vector.
if( is.list( initial ) ){
lop <- rep( NA, length( initial ) )
for( j in 1:length( initial ) ){
if( is.vector( initial[[j]] ) == FALSE ){ stop( "initial must be a vector or a list of vectors." ) }
lop[j] <- length( initial[[j]] )
}
init <- unlist( initial, use.names = FALSE )
}else{
if( is.vector( initial ) ){
lop <- length( initial )
}else{
stop( "initial must be a vector or a list of vectors." )
}
init <- initial
}
# Lower and upper should now be lists, then they need unlisting.
if( is.list( lower ) ){ lower <- unlist( lower, use.names = FALSE ) }
if( is.list( upper ) ){ upper <- unlist( upper, use.names = FALSE ) }
# Optimisation function criteria.
if( identical( lop, 1 ) ){
if( identical( method, "Brent" ) == FALSE ){
stop( "Method of optimisation in function optim for correlation lengths (ML) should be Brent if the optimisation is over a single dimension." )
}
}
if( identical( method, "Brent" ) &
( identical( typeof( lower ), "double" ) == FALSE | identical( typeof( upper ), "double" ) == FALSE |
identical( lower, -Inf ) | identical( upper, Inf ) ) ){
stop( "If the method of optimisation is Brent, then a finite upper and lower value must be provided (take into account the log transformation)" )
}
if( identical( typeof( lower ), "double" ) & min( lower ) <= 0.0001 & identical( lower, -Inf ) == FALSE ){
stop( "lower must be greater than 0.0001 as a result of the log transformation applied for optimisation.")
}
# Obtain the log initial value.
log_init <- log( init - 0.0001 )
log_init
# Obtain the log lower limit.
if( identical( lower, -Inf ) ){
loglower <- lower
}else{
loglower <- log( lower - 0.0001 )
}
# Obtain the log upper limit.
if( identical( upper, Inf ) ){
logupper <- upper
}else{
logupper <- log( upper - 0.0001 )
}
# Obtain G from mean_function_model if required.
if( identical( G, NA ) ){
# Obtain model matrix G from mean_function_model.
G <- NetworkPPBLE::model_matrix( x = x, model = mean_function_model )
}
# number of training points
n <- NROW( fx )
# Number of output components.
k <- NCOL( fx )
# number of regression components.
q <- ncol( G )
# Number of variables.
p <- NCOL( x )
c(n,k,q,p)
f <- function(x){ c( x[2] * sin( x[1] ) + x[1] * cos( x[2] ), 2 * x[1] + 3 * x[2] / x[1] ) }
x <- matrix( runif( 60, 0.2, 1.2 ), ncol = 2 )
fx <- t( apply( x, 1, f ) )
# Check input conditions.
if( NROW ( x ) != NROW ( fx ) ){ stop( "The number of rows of x and fx must be the same." ) }
if( identical( G, NA ) & identical( mean_function_model, NA ) ){ stop( "G and mean_function_model can't both be given as NAs." ) }
# Check that initial is a vector or a list of vectors.  If initial is a list, find the length of each of its elements and store as a vector.
if( is.list( initial ) ){
lop <- rep( NA, length( initial ) )
for( j in 1:length( initial ) ){
if( is.vector( initial[[j]] ) == FALSE ){ stop( "initial must be a vector or a list of vectors." ) }
lop[j] <- length( initial[[j]] )
}
init <- unlist( initial, use.names = FALSE )
}else{
if( is.vector( initial ) ){
lop <- length( initial )
}else{
stop( "initial must be a vector or a list of vectors." )
}
init <- initial
}
# Lower and upper should now be lists, then they need unlisting.
if( is.list( lower ) ){ lower <- unlist( lower, use.names = FALSE ) }
if( is.list( upper ) ){ upper <- unlist( upper, use.names = FALSE ) }
# Optimisation function criteria.
if( identical( lop, 1 ) ){
if( identical( method, "Brent" ) == FALSE ){
stop( "Method of optimisation in function optim for correlation lengths (ML) should be Brent if the optimisation is over a single dimension." )
}
}
if( identical( method, "Brent" ) &
( identical( typeof( lower ), "double" ) == FALSE | identical( typeof( upper ), "double" ) == FALSE |
identical( lower, -Inf ) | identical( upper, Inf ) ) ){
stop( "If the method of optimisation is Brent, then a finite upper and lower value must be provided (take into account the log transformation)" )
}
if( identical( typeof( lower ), "double" ) & min( lower ) <= 0.0001 & identical( lower, -Inf ) == FALSE ){
stop( "lower must be greater than 0.0001 as a result of the log transformation applied for optimisation.")
}
# Obtain the log initial value.
log_init <- log( init - 0.0001 )
# Obtain the log lower limit.
if( identical( lower, -Inf ) ){
loglower <- lower
}else{
loglower <- log( lower - 0.0001 )
}
# Obtain the log upper limit.
if( identical( upper, Inf ) ){
logupper <- upper
}else{
logupper <- log( upper - 0.0001 )
}
# Obtain G from mean_function_model if required.
if( identical( G, NA ) ){
# Obtain model matrix G from mean_function_model.
G <- NetworkPPBLE::model_matrix( x = x, model = mean_function_model )
}
# number of training points
n <- NROW( fx )
# Number of output components.
k <- NCOL( fx )
# number of regression components.
q <- ncol( G )
# Number of variables.
p <- NCOL( x )
c(n,k,q,p)
# Put the formals of the first two elements of CF as x.
formals( CF )[1:2] <- list( x, x )
# CV splits - given as a matrix.
if( nrow( x ) < V_set_size * V_splits ){
V_samples <- matrix( sample( 1:nrow( x ), V_set_size * V_splits, replace = TRUE ), nrow = V_splits )
}else{
V_samples <- matrix( sample( 1:nrow( x ), V_set_size * V_splits ), nrow = V_splits )
}
V_samples
replicate(10, sample(10))
replicate(10, sample(10,3))
# CV splits - given as a matrix.
if( nrow( x ) < V_set_size * V_splits ){
V_samples <- t( replicate( V_splits, sample( 1:nrow( x ), V_set_size ) ) )
}else{
V_samples <- matrix( sample( 1:nrow( x ), V_set_size * V_splits ), nrow = V_splits )
}
V_samples
# Define Log Likelihood function.
CV_accuracy <- function( logz ){
# Turn logz into z.
z <- exp( logz ) + 0.0001
# z needs to be a list.
z <- QuickFunc::vec_to_list( z, lop = lop )
# Assign the value of z to para_to_optim.
for( i in 1:length( para_to_optim ) ){ CF_para[[para_to_optim[i]]] <- z[[i]] }
# Calculate the correlation matrix.
C <- do.call( CF, CF_para )
# Matrix for the expected values.
E_fxi <- matrix( NA, nrow = V_splits * V_set_size, ncol = k )
for( i in 1:V_splits ){
ss <- V_samples[i,]
training_points <- x[-ss,,drop=FALSE]
test_points <- x[ss,,drop=FALSE]
training_runs <- fx[-ss,]
test_runs <- fx[ss,]
# G - model matrix.
G_train <- G[-ss,,drop=FALSE]
g_test <- G[ss,,drop=FALSE]
# Correlation matrix
C_train <- C[-ss,-ss]
c_test <- C[ss,-ss,drop=FALSE]
# Correlation matrix inverse.
L <- t( chol( C_train ) )
Cinv <- solve( t( L ), solve( L ) )
# GLS estimate for beta
betahatGLSestimation <- NetworkPPBLE::GLSbeta( fx = training_runs, C = C_train, G = G_train )
betahatGLS <- betahatGLSestimation$betahatGLS
# model residuals: res = F - G %*% E_F[beta]
res <- training_runs - G_train %*% betahatGLS
# Run the emulator for point i constructed using all of the other points.
gx_EF_beta <- g_test %*% betahatGLS
cx_Cinv <- c_test %*% Cinv
# Equation for E_ux.
E_ux <- cx_Cinv %*% res
# Store the emulator output expectation in the matrix.
E_fxi[( V_set_size * ( i - 1 ) + 1 ):( V_set_size * i ),] <- gx_EF_beta + E_ux
}
# Sum of the squares of the error terms.
SS <- sum( ( fx[ c( t( V_samples ) ), ] - E_fxi )^2 )
# Return the sum of the squares.
return( SS )
}
logz <- log_init
logz
# Turn logz into z.
z <- exp( logz ) + 0.0001
z
# z needs to be a list.
z <- QuickFunc::vec_to_list( z, lop = lop )
z
# Assign the value of z to para_to_optim.
for( i in 1:length( para_to_optim ) ){ CF_para[[para_to_optim[i]]] <- z[[i]] }
# Calculate the correlation matrix.
C <- do.call( CF, CF_para )
# Matrix for the expected values.
E_fxi <- matrix( NA, nrow = V_splits * V_set_size, ncol = k )
dim(E_fxi)
i
ss <- V_samples[i,]
ss
training_points <- x[-ss,,drop=FALSE]
test_points <- x[ss,,drop=FALSE]
training_runs <- fx[-ss,]
test_runs <- fx[ss,]
dim(training_runs)
dim(test_points)
# G - model matrix.
G_train <- G[-ss,,drop=FALSE]
g_test <- G[ss,,drop=FALSE]
dim(G)
# Obtain model matrix G from mean_function_model.
G <- NetworkPPBLE::model_matrix( x = x, model = mean_function_model )
# number of regression components.
q <- ncol( G )
# G - model matrix.
G_train <- G[-ss,,drop=FALSE]
g_test <- G[ss,,drop=FALSE]
dim(G)
# Correlation matrix
C_train <- C[-ss,-ss]
c_test <- C[ss,-ss,drop=FALSE]
# Correlation matrix inverse.
L <- t( chol( C_train ) )
Cinv <- solve( t( L ), solve( L ) )
# GLS estimate for beta
betahatGLSestimation <- NetworkPPBLE::GLSbeta( fx = training_runs, C = C_train, G = G_train )
betahatGLS <- betahatGLSestimation$betahatGLS
# model residuals: res = F - G %*% E_F[beta]
res <- training_runs - G_train %*% betahatGLS
# Run the emulator for point i constructed using all of the other points.
gx_EF_beta <- g_test %*% betahatGLS
cx_Cinv <- c_test %*% Cinv
# Equation for E_ux.
E_ux <- cx_Cinv %*% res
E_ux
# Store the emulator output expectation in the matrix.
E_fxi[( V_set_size * ( i - 1 ) + 1 ):( V_set_size * i ),] <- gx_EF_beta + E_ux
E_fxi
# Define Log Likelihood function.
CV_accuracy <- function( logz ){
# Turn logz into z.
z <- exp( logz ) + 0.0001
# z needs to be a list.
z <- QuickFunc::vec_to_list( z, lop = lop )
# Assign the value of z to para_to_optim.
for( i in 1:length( para_to_optim ) ){ CF_para[[para_to_optim[i]]] <- z[[i]] }
# Calculate the correlation matrix.
C <- do.call( CF, CF_para )
# Matrix for the expected values.
E_fxi <- matrix( NA, nrow = V_splits * V_set_size, ncol = k )
for( i in 1:V_splits ){
ss <- V_samples[i,]
training_points <- x[-ss,,drop=FALSE]
test_points <- x[ss,,drop=FALSE]
training_runs <- fx[-ss,]
test_runs <- fx[ss,]
# G - model matrix.
G_train <- G[-ss,,drop=FALSE]
g_test <- G[ss,,drop=FALSE]
# Correlation matrix
C_train <- C[-ss,-ss]
c_test <- C[ss,-ss,drop=FALSE]
# Correlation matrix inverse.
L <- t( chol( C_train ) )
Cinv <- solve( t( L ), solve( L ) )
# GLS estimate for beta
betahatGLSestimation <- NetworkPPBLE::GLSbeta( fx = training_runs, C = C_train, G = G_train )
betahatGLS <- betahatGLSestimation$betahatGLS
# model residuals: res = F - G %*% E_F[beta]
res <- training_runs - G_train %*% betahatGLS
# Run the emulator for point i constructed using all of the other points.
gx_EF_beta <- g_test %*% betahatGLS
cx_Cinv <- c_test %*% Cinv
# Equation for E_ux.
E_ux <- cx_Cinv %*% res
# Store the emulator output expectation in the matrix.
E_fxi[( V_set_size * ( i - 1 ) + 1 ):( V_set_size * i ),] <- gx_EF_beta + E_ux
}
# Sum of the squares of the error terms.
SS <- sum( ( fx[ c( t( V_samples ) ), ] - E_fxi )^2 )
# Return the sum of the squares.
return( SS )
}
system.time( CV_accuracy(logz) )
CV_accuracy(logz)
# Carry out the optimisation for theta - note that the optimisation happens on a log scale.
cl_optimisation <- stats::optim( log_init, CV_accuracy, control = list( fnscale = -1 ), method = method, lower = loglower, upper = logupper )
cl_optimisation
# Extract zhat - note the transformation back to the original scale.
z_hat <- exp( cl_optimisation$par ) + 0.0001
# z needs to be a list.
z_hat <- QuickFunc::vec_to_list( z_hat, lop = lop )
z_hat
source('~/Documents/Academic Work/R Functions in Packages/NetworkPPBLE/R/CL_CV.r')
devtools::load_all(".")
document()
rm(list = c("CL_CV"))
devtools::load_all(".")
document()
library(NetworkPPBLE)
devtools::load_all(".")
document()
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
library(NetworkPPBLE)
f <- function(x){ c( x[2] * sin( x[1] ) + x[1] * cos( x[2] ), 2 * x[1] + 3 * x[2] / x[1] ) }
x <- matrix( runif( 60, 0.2, 1.2 ), ncol = 2 )
fx <- t( apply( x, 1, f ) )
CL_CV( CF = NetworkPPBLE::GaussianCF,
CF_para = list( delta = 0.0001 ),
para_to_optim = "theta",
x = x,
fx = fx,
mean_function_model = 1,
initial = rep( 1, 2 )
)
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
use_r( "s2CV.r" )
?Prediction_diagnostics
source('~/Documents/Academic Work/R Functions in Packages/Package Building Libraries.R')
devtools::load_all(".")
document()
library(NetworkPPBLE)
